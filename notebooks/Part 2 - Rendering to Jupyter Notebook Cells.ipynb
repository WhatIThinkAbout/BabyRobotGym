{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[A Baby Robot's Guide To Reinforcement Learning](https://towardsdatascience.com/tagged/baby-robot-guide)__\n",
    "\n",
    "# Creating a Custom Gym Environment for Jupyter Notebooks\n",
    "## Part 2: Rendering to Jupyter Notebook Cells\n",
    "\n",
    "<center><img src=\"images/part2_cover_opt.gif\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook on Binder:\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/WhatIThinkAbout/BabyRobotGym/HEAD?labpath=notebooks%2FBabyRobot_API.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "> <b>Updated 7th January 2023:</b>\n",
    "> \n",
    "> Development of the Open AI Gym library for Reinforcement Learning, which is the base framework originally described in this article,has stopped. It has now been replaced by _[Gymnasium](https://github.com/Farama-Foundation/Gymnasium)_, a new package managed by the _[Farama Foundation](https://farama.org/Announcing-The-Farama-Foundation)_. \n",
    ">\n",
    "> In most cases this new framework remains the same as the original, but there have been a few subtle changes to the API. Consequently this article and its accompanying code samples have been updated to take account of these changes and to make use of this latest framework.\n",
    ">\n",
    "> Therefore, although the framework is still referred to as 'Gym', this actually means the new 'Gymnasium' version of the library.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In _[Part One](https://towardsdatascience.com/creating-a-custom-gym-environment-for-jupyter-notebooks-e17024474617)_, we saw how a custom Gym environment for **Reinforcement Learning** (_RL_) problems could be created, simply by extending the Gym base class and implementing a few functions. However, the custom environment we ended up with was a bit basic, with only a simple text output. \n",
    "\n",
    "So, in this part, we'll extend this simple environment by adding graphical rendering. Additionally, this rendered output will be explicitly targeted at _Jupyter Notebooks_, producing a graphical representation of the environment directly into the notebook cells.\n",
    "\n",
    "\n",
    "<center><img src=\"images/green_babyrobot_small.gif\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the ipycanvas Library\n",
    "\n",
    "When running a Reinforcement Learning problem in a _Jupyter Notebook_, it's very easy to write text into the notebook cell to show how things are progressing. However, given the large amount of information that can be generated over time, a much clearer representation can be obtained by creating a graphical view of the environment.\n",
    "\n",
    "Quite often this graphical view is generated by taking snapshot images of the environment at each time-step and then joining these together, at the end of the episode, to create a short movie. This can then be played back within the notebook to see how things progressed.\n",
    "\n",
    "The downside with this approach is that you need to wait for the movie to be created. Ideally we want to see the changes that occur in our environment happening in real time. We need something that can be added to a notebook cell, then drawn to and updated as actions take place. \n",
    "This exact functionality can be achieved using the _[HTML canvas element](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API)_, which can be accessed within a _Jupyter Notebook_ using the excellent **[ipycanvas](https://ipycanvas.readthedocs.io/en/latest/)** library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries required to run the notebook code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# uncomment this if the code has been cloned from github\n",
    "# set the path so we can import from the root directory\n",
    "# import sys\n",
    "# sys.path.insert(0, '../')\n",
    "\n",
    "# install the babyrobot gym environment if code not cloned\n",
    "%pip install babyrobot --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from time import sleep\n",
    "from ipywidgets import Layout, Play, Image, IntProgress, HBox, VBox, link\n",
    "from IPython.display import Image as PyImage\n",
    "\n",
    "# import the babyrobot library to get access to the previous environments and utilities\n",
    "import babyrobot\n",
    "\n",
    "# alias gymnasium to make it compatible with existing code that refers to 'gym'\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the Gymnasium 'check_env' function to check the environment\n",
    "# - returns nothing if the environment is verified as ok\n",
    "from gymnasium.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:\n",
    "\n",
    "The first thing we're going to need to create our _**Baby Robot Grid World**_, is the actual \"world\", where all the action takes place. At its most basic, this is just a coloured rectangle. This can be created really easily in _ipycanvas_ by simply defining a canvas and then specifying the size and colour of rectangle to draw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipycanvas import Canvas,hold_canvas\n",
    "\n",
    "cell_pixels = 64           # pixel dimensions of a grid square   \n",
    "grid_width  = 3            # number of horizontal cells\n",
    "grid_height = 3            # number of vertical cells \n",
    "\n",
    "width_pixels  = grid_width  * cell_pixels  # total horizontal pixels\n",
    "height_pixels = grid_height * cell_pixels  # total vertical pixels\n",
    "\n",
    "canvas = Canvas(width=width_pixels, height=height_pixels, sync_image_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we've imported the _ipycanvas_ library, then defined the dimensions of the grid world that we're going to create. This will be a 3x3 grid, where each cell is a square of 64-pixels. Using these dimensions we can then create our canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_base(canvas):\n",
    "  ''' fill the supplied canvas with orange '''\n",
    "  canvas.fill_style = 'orange' \n",
    "  canvas.fill_rect(0, 0, canvas.width, canvas.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially the canvas will be blank, so to actually see the canvas we need to draw something. In the '_draw_base_' function, shown above, the fill colour is set to be orange and then this is used to draw a rectangle covering the complete canvas area.\n",
    "\n",
    "After calling this function, the final line, '_canvas_', just draws the completed canvas into the notebook cell, as shown in _Figure 1_ below. This square will act as the base of our grid-world. Pretty exciting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb0b55838da429ba84d5a4e8e458398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=192, sync_image_data=True, width=192)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_base(canvas)  \n",
    "canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1: The basic canvas world.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Grid\n",
    "\n",
    "The next thing that any self-respecting Grid World is going to need is an actual grid. Again this can be easily achieved in _ipycanvas_ by drawing a few dashed lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid( canvas ):\n",
    "  # with hold_canvas(canvas):\n",
    "    canvas.stroke_style = '#777' # grid line color - medium gray\n",
    "    canvas.line_width = 1\n",
    "    canvas.set_line_dash([4,8])    \n",
    "\n",
    "    # draw the grid onto the canvas\n",
    "    for y in range(grid_height):   \n",
    "      for x in range(grid_width):   \n",
    "        canvas.stroke_rect(cell_pixels * x, cell_pixels * y, cell_pixels, cell_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've defined a function that sets up the canvas properties to draw a 1 pixel wide, dashed, grey line. Then we simply draw a rectangle for each cell in the grid, which gives us the output shown in _Figure 2_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd09c53b7262486fb988ce7641d4e787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=192, sync_image_data=True, width=192)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "canvas = Canvas(width=width_pixels, height=height_pixels, sync_image_data=True)\n",
    "draw_base(canvas) \n",
    "draw_grid( canvas )\n",
    "canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 2: The basic grid world.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_border(canvas):\n",
    "  canvas.stroke_style = 'black'\n",
    "  canvas.line_width = 5\n",
    "  canvas.set_line_dash([0,0])\n",
    "  canvas.stroke_rect(0,0,width_pixels,height_pixels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the look of our grid world by adding a border around the outside. This is simply a black rectangle, with slightly thicker lines than the grid, and is defined in the 'draw_border' function. This produces the output shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408c71cf0a7a47b9b6190f2ed8def852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=192, sync_image_data=True, width=192)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "canvas = Canvas(width=width_pixels, height=height_pixels, sync_image_data=True)\n",
    "draw_base(canvas) \n",
    "draw_grid( canvas )\n",
    "draw_border(canvas)\n",
    "canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 3: The grid world with an added border.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an Animated Image\n",
    "\n",
    "The final thing that our _Baby Robot Grid World_ is going to need is a _Baby Robot_, and preferably one that moves! Since we want our robot to move over the top of the grid level, without damaging anything we've already drawn, we'll use a separate canvas for our robot animation. \n",
    "\n",
    "This is easily achieved using the _**MultiCanvas**_ element. With this we can stack as many canvases as we want, and draw to each one separately, to build up our complete environment. This is shown below, where we've defined the _MultiCanvas_ to have 2 layers and then used the functions from above to recreate the grid world on the first of these layers (layer index zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6da0da7d4a443e0b70485865cf29e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=192, sync_image_data=True, width=192)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipycanvas import MultiCanvas\n",
    "\n",
    "layers = 2\n",
    "multi_canvas = MultiCanvas(layers,width=width_pixels, height=height_pixels, sync_image_data=True)\n",
    "draw_base(multi_canvas[0])  \n",
    "draw_grid(multi_canvas[0])\n",
    "draw_border(multi_canvas[0])\n",
    "multi_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can load in our Baby Robot image and create a very simple animation, drawing our animation onto the upper canvas (index = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_size = 64\n",
    "baby_robot = Image.from_file('images/baby_robot.png')  \n",
    "\n",
    "# animate an image on the canvas\n",
    "def animate_robot( canvas ):  \n",
    "  canvas.clear()\n",
    "  y = robot_size + 2\n",
    "  for x in range(-robot_size,200,2):   \n",
    "    with hold_canvas(canvas):\n",
    "      canvas.clear_rect(x, y, robot_size)                        \n",
    "      canvas.draw_image(baby_robot, x, y )       \n",
    "    sleep(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make Baby Robot move across the screen we use a simple loop that clears the previous image before drawing the next one. Since there's some padding on the image we can simply clear the area where we want to draw the new image. Both of these operations are tied together using '_hold_canvas_' which makes things slightly smoother (for more advanced animations check out the _[ipycanvas documentation](https://ipycanvas.readthedocs.io/en/latest/animations.html)_).\n",
    "\n",
    "The final Baby Robot Grid World is shown in Figure 4, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6da0da7d4a443e0b70485865cf29e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=192, image_data=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\xc0\\x08\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 4. Baby Robot in the Grid World.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to make Baby Robot move\n",
    "animate_robot( multi_canvas[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Graphical Grid Level\n",
    "\n",
    "Using the _ipycanvas_ library, and the basic drawing routines described above, we can create classes that encapsulate all of the functionality required to draw a graphical grid level for our custom Gym environment. \n",
    "\n",
    "As part of this, we have two main classes:\n",
    "\n",
    "* _**GridLevel**_: to manage the drawing and querying of the grid level.\n",
    "* _**RobotDraw**_: to draw Baby Robot onto the grid at a particular location and to do the animation as he moves between cells.\n",
    "\n",
    "The full code for both of these classes can be found on _[Github](https://github.com/WhatIThinkAbout/BabyRobotGym/tree/main/babyrobot/envs/lib)_.\n",
    "\n",
    "In the code below we import these two classes and then use them to draw a default 3x3 grid level, onto which we add Baby Robot, positioned at cell [1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3079779e56f54b879c5d93869bde0b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=196)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from babyrobot.envs.lib import GridLevel\n",
    "from babyrobot.envs.lib import RobotDraw\n",
    "\n",
    "# draw the default grid level\n",
    "level = GridLevel()\n",
    "\n",
    "# add Baby Robot\n",
    "robot = RobotDraw(level)\n",
    "robot.set_cell_position([1,1])\n",
    "robot.draw()\n",
    "\n",
    "# show all environment canvases\n",
    "level.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 5: A default Baby Robot grid world level.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a default _Baby Robot_ grid world level that we can use to create a graphical rendering function for our Gym environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a graphical Gym render function\n",
    "\n",
    "At the end of the first part of this series on creating a custom Gym environment we'd ended up with a render function that produced this:\n",
    "\n",
    "<center><img src=\"images/V2_output.png\"/></center>\n",
    "<center><i>Figure 5: The output from version 2 of BabyRobotEnv's 'render' function.</i></center>\n",
    "\n",
    "While providing all the important information about the current state of the environment, it's not very exciting. Additionally, it's a lot harder to visualise how the episode progressed. By looking at the coordinates at each time step you can sort of imagine how Baby Robot moved through the grid, but things would be much clearer if we could actually see this happening.\n",
    "\n",
    "As we've seen, real time graphics can be created in a _Jupyter Notebook_ cell using _ipycanvas_, so we can replace the current text-base render function with one that shows a graphical view of the environment and update this as changes occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babyrobot.envs import BabyRobotEnv_v2\n",
    "from babyrobot.envs.lib import Actions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' the first graphical environment '''\n",
    "class BabyRobotEnv_v3( BabyRobotEnv_v2 ):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # graphical creation of the level\n",
    "      self.level = GridLevel( **kwargs )\n",
    "\n",
    "      # add baby robot\n",
    "      self.robot = RobotDraw(self.level,**kwargs)\n",
    "      self.robot.draw()\n",
    "\n",
    "  def reset(self, seed=None, return_info=False, options=None):\n",
    "      super().reset(seed=seed)\n",
    "      # reset Baby Robot's position in the grid\n",
    "      self.robot.set_cell_position(self.initial_pos)\n",
    "      self.robot.reset()\n",
    "      self.x = self.initial_pos[0]\n",
    "      self.y = self.initial_pos[1]\n",
    "      info = {}\n",
    "      return np.array([self.x,self.y]),info\n",
    "\n",
    "  def render(self, action=0, reward=0 ):\n",
    "      ''' render as an HTML5 canvas '''\n",
    "      print(f\"{Actions(action): <5}: ({self.x},{self.y}) reward = {reward}\")\n",
    "\n",
    "      # move baby robot to the current position\n",
    "      self.robot.move(self.x,self.y)\n",
    "      return self.level.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've done previously, the new class inherits from the previous version of the environment (in this case from <i>BabyRobotEnv_v2</i>), which gives us all the functionality of the Gym base class, plus the extra stuff we added in the previous iterations. We then just need to provide new versions of the functions we want to replace, which in this case are as follows:\n",
    "\n",
    "* <b><i>\\_\\_init\\_\\_</i></b> : contains the instances of our 'GridLevel' and 'RobotDraw' classes that we need for drawing the grid and Baby Robot respectively.\n",
    "\n",
    "* <b><i>reset</i></b> : puts both Baby Robot and the environment back to the initial position.\n",
    "\n",
    "* <b><i>render_</i></b> : moves Baby Robot to the new position (where the position has been calculated in the Gym interface's 'step' function, defined in BabyRobotEnv_v2) and draws the level. This will animate the movement as Baby Robot moves from one cell to the next.\n",
    "\n",
    "Now when we create an instance of this environment and call it's render function, we see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay : (0,0) reward = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfe99fa0eaa4ab2b442e6f50ddbf58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=196)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = BabyRobotEnv_v3()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay : (0,0) reward = -1\n",
      "West : (0,0) reward = -1\n",
      "East : (1,0) reward = -1\n",
      "East : (2,0) reward = -1\n",
      "Stay : (2,0) reward = -1\n",
      "South: (2,1) reward = -1\n",
      "West : (1,1) reward = -1\n",
      "East : (2,1) reward = -1\n",
      "South: (2,2) reward = 0\n"
     ]
    }
   ],
   "source": [
    "# initialize the environment\n",
    "env.reset()\n",
    "\n",
    "terminated = False\n",
    "while not terminated: \n",
    "\n",
    "  # choose a random action\n",
    "  action = env.action_space.sample()   \n",
    "\n",
    "  # take the action and get the information from the environment\n",
    "  new_state, reward, terminated, truncated, info = env.step(action)\n",
    "  \n",
    "  # show the current position and reward\n",
    "  env.render(action=action, reward=reward) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better, when we run our standard reinforcement learning loop, shown above, we now get to see Baby Robot moving around the environment. Baby Robot is currently taking randomly sampled actions in his quest to find the exit, so each episode will follow a different path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State specific action spaces\n",
    "\n",
    "If you take a look again at the _BabyRobotEnv_v3 'render'_ function, you'll see that we're still printing the action, position and reward for each time step. So, in addition to the new graphical output, we're still getting the text output from version 2 of our environment. Additionally, if you examine this text output, you'll see entries such as the first line in _Figure 5_: \n",
    "\n",
    "_\"North: (0,0) reward = -1\"_\n",
    "\n",
    "In other words, Baby Robot was in the initial start square (0,0) and then chose to move North, which would take him straight into a wall!\n",
    "\n",
    "Although he's only a baby, he's not stupid, so should only choose actions that are valid. We can achieve this by introducing a state specific action space where, rather than simply choosing from all of the actions, the action that is returned depends on the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dynamic(gym.Space):\n",
    "\n",
    "  def __init__(self, action_list = []):\n",
    "      ' set the list of initially available actions '      \n",
    "      self.set_actions(action_list)\n",
    "      \n",
    "  def sample(self):\n",
    "      ' select a random action from the set of available actions '\n",
    "      return np.random.choice(self.available_actions)    \n",
    "    \n",
    "  def set_actions(self,actions):\n",
    "      self.available_actions = actions\n",
    "      self.n = len(actions)    \n",
    "      \n",
    "  def get_available_actions(self):\n",
    "      return [str(action) for action in self.available_actions] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above we've created a custom _[Gym Space](https://www.gymlibrary.ml/content/spaces/)_. We'll use this to store the actions available in the current state and then, when '_sample_' is called, we'll randomly select one of these actions.\n",
    "\n",
    "Using this class we can enhance our previous environment so that, when a new state is entered, it sets up the possible actions for that state. This is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babyrobot.envs.lib import Direction\n",
    "\n",
    "class BabyRobotEnv_v4( BabyRobotEnv_v3 ):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # initially no actions are available\n",
    "      self.dynamic_action_space = Dynamic()\n",
    "\n",
    "      # set the initial position and available actions\n",
    "      self.reset()\n",
    "\n",
    "\n",
    "  def get_available_actions( self ):\n",
    "      ''' test which actions are allowed at the specified grid state '''\n",
    "\n",
    "      # get the available actions from the grid level\n",
    "      direction_value = self.level.get_directions(self.x,self.y)\n",
    "\n",
    "      # convert the grid directions into environment actions\n",
    "      action_list = []\n",
    "      if direction_value & Direction.North: action_list.append( Actions.North )\n",
    "      if direction_value & Direction.South: action_list.append( Actions.South )\n",
    "      if direction_value & Direction.East:  action_list.append( Actions.East )\n",
    "      if direction_value & Direction.West:  action_list.append( Actions.West )\n",
    "      return action_list\n",
    "\n",
    "\n",
    "  def set_available_actions( self ):\n",
    "      ' set the list of available actions into the action space '\n",
    "      action_list = self.get_available_actions()\n",
    "      self.dynamic_action_space.set_actions( action_list )\n",
    "\n",
    "\n",
    "  def show_available_actions( self ):\n",
    "      ''' print the set of avaiable actions for current state '''\n",
    "      available_actions = str(self.dynamic_action_space.get_available_actions()).replace(\"'\",\"\")\n",
    "      print(f\"({self.x},{self.y}) {available_actions:29}\",end=\"\")\n",
    "\n",
    "\n",
    "  def take_action(self, action):\n",
    "      ''' apply the supplied action '''\n",
    "\n",
    "      # call the parent class to take the action and update the position\n",
    "      super().take_action( action )\n",
    "\n",
    "      # set the available actions for the new state\n",
    "      self.set_available_actions()\n",
    "\n",
    "\n",
    "  def reset(self, seed=None, return_info=False, options=None):\n",
    "      # reset Baby Robot's position in the grid\n",
    "      observation,info = super().reset(seed=seed)\n",
    "      self.set_available_actions()\n",
    "      return observation,info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we inherit from the previous environment (in this case <i>BabyRobotEnv_v3</i>), so that we can build on its functionality. We then add an instance of the 'Dynamic' class and, each time the '<i>take_action</i>' function is called, we populate this with the actions available for the current state.\n",
    "\n",
    "As a result, when an action is sampled for a particular state, it will be drawn from the set of valid actions, that don't result in Baby Robot walking into a wall. \n",
    "\n",
    "For example, for the start state, calling BabyRobotEnv_v4's '<i>show_available_actions</i>' function returns the actions South and East. Similarly, for grid position (2,1), shown in _Figure 8_, the available actions are North, South or West."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,0) [South, East]                Stay : (0,0) reward = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b32f65cd8044a4b62ceaeba59085c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=196)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the default environment\n",
    "env = BabyRobotEnv_v4()\n",
    "env.show_available_actions()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,1) [North, South, West]         Stay : (2,1) reward = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f24aa45ed34091b2a98cac70be3bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=296)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = BabyRobotEnv_v4(**{'initial_pos':[2,1],'add_compass':True})\n",
    "env.show_available_actions()\n",
    "env.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i>Figure 8: Grid position (2,1) where the available actions are North, South or West.</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.level.save(\"images/position_2_1.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering and checking a local environment class\n",
    "\n",
    "To check that our new environment conforms to the Gym API standard we can use the Gymnasium '<i>check_env</i>' function. If this returns no warnings then we're all good.\n",
    "\n",
    "However, to supply our environment to this function, we first need to call '_gym.make_' to make the environment, but before we can do this we need to have registered the environment for Gymnasium to know about it.\n",
    "\n",
    "In the first part of this article we saw how to do this when the custom environment was contained in its own python file. In this case the '<i>entry_point</i>' supplied to the '_register_' function defines the file and class name.\n",
    "\n",
    "Registering a local class is slightly different. In this case the '<i>entry_point</i>' is just the class name rather than a string. So, in this case, we can register and check the <b><i>BabyRobotEnv_v4</i></b> class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay : (0,0) reward = 0\n"
     ]
    }
   ],
   "source": [
    "# register the local custom environment class\n",
    "from gymnasium.envs.registration import register\n",
    "register( id='BabyRobotEnv-v4', entry_point=BabyRobotEnv_v4 )\n",
    "\n",
    "# make the environment\n",
    "env = gym.make(\"BabyRobotEnv-v4\")\n",
    "\n",
    "# check the environment conforms to the API standard\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing the graphical environment\n",
    "\n",
    "While it's useful to be able to see the text output, giving the details for each action, it's not very nice that it generates an ever increasing list of text, which eventually swamps the notebook cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BabyRobotEnv_v5( BabyRobotEnv_v4 ):\n",
    "  \n",
    "  def __init__(self, **kwargs):\n",
    "      super().__init__(**kwargs)  \n",
    "  \n",
    "  def render(self, info=None):                 \n",
    "      ''' render as an HTML5 canvas '''           \n",
    "      # move baby robot to the current position\n",
    "      self.robot.move(self.x,self.y) \n",
    "      # write the info to the grid side-panel      \n",
    "      self.show_info(info) \n",
    "      return self.level.draw()          \n",
    "\n",
    "  def show_info(self,info):\n",
    "      ''' display the supplied information on the grid level '''\n",
    "      self.level.show_info( info )      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register and make the environment\n",
    "register( id='BabyRobotEnv-v5', entry_point=BabyRobotEnv_v5 )\n",
    "env = gym.make(\"BabyRobotEnv-v5\")\n",
    "\n",
    "# check the environment conforms to the API standard\n",
    "# - returns nothing if the environment is verified as ok\n",
    "check_env(env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using a print statement in the '_render_' function we can instead write text directly to the canvas. To do this, we first need to expand the canvas to create a region where the text can be shown. By making use of the '<i>\\_\\_init\\_\\_</i>' function's '_kwargs_' argument, we can supply an object that defines this text region:\n",
    "\n",
    "In the example below we've specified that we'd like a grey side panel with a width approximately equal to the width of the grid level. This then gives the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5344e8e0e89d4cc58a41131dd3862d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=396)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = babyrobot.make(\"BabyRobotEnv-v5\",**{'side_panel':{'width':200,'color':'#ddd'}})\n",
    "env.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(note that here we're using '_babyrobot.make_' as opposed to '_gym.make_' - this is to avoid being forced to call '_env.reset()_' before '_env.render()_' which is a new restriction implemented in the later versions of Gym.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need now is a way to write to this panel, and display the required information, each time '_render_' is called. The next iteration of our environment contains the '<i>show_info</i>' function to do just that.\n",
    "\n",
    "The new '<i>show_info</i>' method calls a function in the underlying '_GridLevel_' class. This takes an information object giving the text to display and the details of where it should go.\n",
    "\n",
    "Previously, in the '<i>render</i>' function, we supplied the action and the reward and then displayed these using a print command:\n",
    "\n",
    "```\n",
    "print(f\"{Actions(action): <5}: ({self.x},{self.y}) reward = {reward}\")\n",
    "```\n",
    "\n",
    "In the new graphical version, we instead create an information object in the main loop and give it to the render function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de8e2a225f44e6bf22bc238f260260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=396)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = babyrobot.make(\"BabyRobotEnv-v5\", **{'side_panel':{'width':200,'color':'#ddd'}})\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the environment, taking random actions\n",
    "env.reset()\n",
    "\n",
    "info = {}\n",
    "terminated = False\n",
    "while not terminated:\n",
    "\n",
    "  # choose a random action\n",
    "  action = env.action_space.sample()\n",
    "\n",
    "  # take the action and get the information from the environment\n",
    "  new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "  # form an information string\n",
    "  info_str = f\"{Actions(action): <5}: {new_state} reward = {reward}\"\n",
    "\n",
    "  # show the current position and reward\n",
    "  env.render(info = {'side_info': [((10,10),info_str)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the Challenge\n",
    "\n",
    "While our new graphical output from the custom Gym environment may look nice, it's not exactly a very hard Reinforcement Learning challenge. To make things more difficult we need to add a few obstacles for Baby Robot to negotiate.\n",
    "\n",
    "### Adding Walls:\n",
    "We can supply an array of wall definitions when creating the environment. Each item in this array defines the grid coordinate and side of the cell where the wall should be placed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,0) [South]                      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e151adf65a764832a0b2d60a331bc994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=296)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup = {'add_compass':True}\n",
    "walls = [((0, 0),'E'),\n",
    "         ((2, 2),'W')]\n",
    "setup['walls'] = walls\n",
    "\n",
    "env = BabyRobotEnv_v5(**setup)\n",
    "env.show_available_actions()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i>Figure 11: Adding walls to the environment.</i></center>\n",
    "\n",
    "### Adding Puddles\n",
    "\n",
    "Currently, when moving around the grid, all of Baby Robot's actions are deterministic. For example, in Figure 11 above, Baby Robot currently only has one possible action from the Start state, and that's to head South. When he takes this action he'll definitely end up in the cell below and will receive a reward of -1 for taking this action.\n",
    "\n",
    "Many RL problems instead consider probabilistic environments where, when an action is taken, it's not guaranteed that you end up in the target state nor that you get the expected reward (see the article on \"_[Markov Decision Processes and Bellman Equations](https://towardsdatascience.com/markov-decision-processes-and-bellman-equations-45234cce9d25)_\" for more information on this). We can introduce this randomness to the grid world by adding puddles. When Baby Robot encounters one of these there's a chance he can skid, in which case he'll end up in a different cell than the one he was trying to reach. Additionally, it takes Baby Robot longer to move through puddles, and so the reward for moving into a puddle is more negative (i.e. a larger penalty).\n",
    "\n",
    "Before we add any puddles we'll make one final change to the environment. In the '<i>take_action</i>' function we'll check if the action resulted in the desired target being reached. Then, in the '_step_' function, we'll make use of the Gym interface's 'info' object to return this information. This will allow us to monitor the effect of Baby Robot moving into a puddle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BabyRobotEnv_v6( BabyRobotEnv_v5 ):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "  def take_action(self, action):\n",
    "      ''' apply the supplied action\n",
    "          returns: - the reward obtained for taking the action\n",
    "                   - flag indicating if the target state was reached\n",
    "      '''\n",
    "      # convert the action into a direction bitfield\n",
    "      direction = Direction.from_action(action)\n",
    "\n",
    "      # calculate the postion of the next state and the reward for moving there\n",
    "      next_pos,reward,target_reached = self.level.get_next_state( self.x, self.y, direction )\n",
    "\n",
    "      # store the new position\n",
    "      self.x = next_pos[0]\n",
    "      self.y = next_pos[1]\n",
    "\n",
    "      # update the available actions for the new position\n",
    "      self.set_available_actions()\n",
    "      return reward, target_reached\n",
    "\n",
    "  def step(self, action):\n",
    "\n",
    "      # take the action and update the position\n",
    "      reward, target_reached = self.take_action(action)\n",
    "      obs = np.array([self.x,self.y])\n",
    "\n",
    "      # set the 'terminated' flag if we've reached the exit\n",
    "      terminated = (self.x == self.end[0]) and (self.y == self.end[1])\n",
    "      truncated = False\n",
    "\n",
    "      info = {'target_reached':target_reached}\n",
    "      return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0]), -1, False, False, {'target_reached': False})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BabyRobotEnv_v6()\n",
    "env.step(Actions.Stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register and make the environment\n",
    "register( id='BabyRobotEnv-v6', entry_point=BabyRobotEnv_v6 )\n",
    "env = gym.make(\"BabyRobotEnv-v6\")\n",
    "\n",
    "# check the environment conforms to the API standard\n",
    "# - returns nothing if the environment is verified as ok\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with walls, puddles are specified by giving the coordinates of their grid location. However, puddles exist in the middle of a cell, so a side doesn't need to be specified. Instead the size of the puddle is defined, with 2 possible options which, by default, having the following properties:\n",
    "\n",
    "* 1 = small puddle. Reward = -2, Probability of skidding = 0.4\n",
    "* 2 = large puddle. Reward = -4, Probability of skidding = 0.6\n",
    "\n",
    "If we now run the simple test code, shown below, Baby Robot will try to take 2 steps to the East. The first of these will succeed, since he's moving from the Start square which is dry. However, he's moving into a large puddle so will automatically receive a reward of -4. On his next move he'd like to reach the Exit, so again tries to move East. However, he's now moving out of a large puddle, so there's a 0.6 probability that he'll skid and instead end up in one of the other possible states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,1) [East]                       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a077f6ee264c7ab88fbd40c0c36edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=196, sync_image_data=True, width=396)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup = { 'start':[0,1], 'end': [2,1] , 'add_compass':True }        \n",
    "setup['side_panel'] = {'width':200,'color':'#ddd'}\n",
    "setup['walls'] = [((0, 1),'N'),((0, 1),'S')]\n",
    "setup['puddles'] = [((1,1),2)]\n",
    "\n",
    "env = BabyRobotEnv_v6(**setup)\n",
    "env.show_available_actions()\n",
    "env.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puddle_test():\n",
    "  env.reset()\n",
    "  for step in range(2):\n",
    "    action = Actions.East\n",
    "    new_state, reward, terminated, truncated, info = env.step(action)\n",
    "    info_str = f\"{Actions(action): <5}: {new_state} reward = {reward}\"\n",
    "    target_str = f\"Target Reached = {info['target_reached']}\"\n",
    "    env.render(info = {'side_info': [((10,100),info_str),((10,130),target_str)]})\n",
    "\n",
    "puddle_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Maze\n",
    "\n",
    "Many Grid World problems define mazes that need to be navigated in search of the exit. While we could achieve this by specifying a large array of walls, this would quickly get to be annoying. Therefore we can instead just specify that we'd like to add a maze and supply it with a random seed, which will determine the walls that are created.\n",
    "\n",
    "By default the maze will only have a single path that can be followed to reach the exit. For many RL problems a better challenge is created when several possible options are available and the learning algorithm will need to find the best of these. By removing some of the walls from the maze we can create several routes to the exit. The RL algorithm will then need to find which one of these gets Baby Robot to the exit with the greatest reward.\n",
    "\n",
    "Here, in our final level, we've added pretty much everything! We've specified a larger level of size 8x5 featuring a maze. We've then removed a few walls from this to create several routes to the exit. Then we've added some puddles, just to create more of a challenge. Finally, to make things look nice, we've specified that we'd like to use the '<i>black_orange</i>' theme (all of the colours are fully customizable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c722f2f4414db5b764756143bc513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiCanvas(height=326, sync_image_data=True, width=718)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup = { 'width': 8,\n",
    "          'height': 5,\n",
    "          'add_maze': True,\n",
    "          'maze_seed': 42,\n",
    "          'end': [5,4]\n",
    "        }       \n",
    "walls = [((2, 0),'E'), # remove the east wall at (2,0)\n",
    "         ((2, 2),'E'), # remove the east wall at (2,2)\n",
    "         ((3, 2),'E'), # remove the east wall at (3,2)\n",
    "         ((5, 2),'E')] # add an east wall at (5,2)        \n",
    "setup['walls'] = walls\n",
    "\n",
    "puddles = [((2,2),1),           \n",
    "           ((2,0),1),\n",
    "           ((7,3),1),\n",
    "           ((3,2),2),\n",
    "           ((5,1),2)]\n",
    "setup['puddles'] = puddles\n",
    "\n",
    "setup['grid'] = {'theme': 'black_orange'}\n",
    "setup['side_panel'] = {'width':200}\n",
    "env = BabyRobotEnv_v6(**setup)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the environment, taking random actions\n",
    "env.reset()\n",
    "\n",
    "info = {}\n",
    "terminated = False\n",
    "\n",
    "# run for a maximum of 20 steps\n",
    "for step in range(20):\n",
    "\n",
    "  # choose a random action\n",
    "  action = env.action_space.sample()   \n",
    "\n",
    "  # take the action and get the information from the environment\n",
    "  new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "  # form an information string\n",
    "  info_str = f\"{Actions(action): <5}: {new_state} reward = {reward}\"  \n",
    "    \n",
    "  # show the current position and reward  \n",
    "  env.render(info = {'side_info': [((10,10),info_str),((10,30),f\"Step = {step}\")]})  \n",
    "\n",
    "  if terminated:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, Baby Robot now has a challenging problem, where he must search the maze looking for the exit. When the standard Gym Environment Reinforcement Learning loop is run, Baby Robot will begin to randomly explore the maze, gathering information that he can use to learn how to escape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, given that random actions are being taken, and with the added complication of puddles that can potentially cause skids, it may take Baby Robot some time to locate the exit. To see how a Reinforcement Learning algorithm can be used to find the best route through the maze, check out the _[training notebook](https://colab.research.google.com/github/WhatIThinkAbout/BabyRobotGym/blob/main/notebooks/PPO_Training.ipynb)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Over the course of these two articles we've seen how a custom _Gym Environment_ can be created, with real-time graphical output rendered directly into _Jupyter Notebook_ cells. \n",
    "\n",
    "The _ipycanvas_ library provides direct access to the HTML canvas, where simple graphical components can be combined to produce informative views of the _Reinforcement Learning_ environment.\n",
    "\n",
    "Additionally, by basing this environment on the _Gym API_ we can create _Reinforcement Learning_ problems that are compatible with a host of different out-of-the box learning algorithms. Hopefully these articles have given you all the information you need to start building your own, bespoke, _RL_ environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If you'd just like to have a play with the Baby Robot environment, check out this _[notebook](https://colab.research.google.com/github/WhatIThinkAbout/BabyRobotGym/blob/main/notebooks/BabyRobot_API.ipynb)_ showing the different ways in which Baby Robot Grid Worlds can be created and the components that can be added.\n",
    "\n",
    "---\n",
    "\n",
    "Now that we can create a range of challenging worlds for Baby Robot to explore, all that's left to do is learn how to tackle these problems. The first part of the series on how to do this can be found _[here](https://towardsdatascience.com/state-values-and-policy-evaluation-ceefdd8c2369)_.\n",
    "\n",
    "\n",
    "<center><img src=\"images/green_babyrobot_small.gif\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BabyRobotGym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50f7925c2b527e04ad4ab9285d4738429ed4ef149c3803ef7aee3c43b8d710c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
